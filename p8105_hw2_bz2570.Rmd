---
title: "p8105_hw2_bz2570"
author: "Boran Zhai"
date: "2025-09-30"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(readr)
library(readxl)
library(lubridate)
```

## Problem 1

#### (1) Clean the data in pols-month.csv
Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.
```{r}
pols_month <- read_csv("./data/pols-month.csv") |> 
  janitor::clean_names() |>
  separate(mon, into = c("year", "month", "day"), sep = "-") |>
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day),
    month = month.abb[month],
    president = ifelse(prez_gop == 1, "gop", 
                       ifelse(prez_dem == 1, "dem",NA))
  ) |>
  select(-prez_dem, -prez_gop, -day)
pols_month
```

#### (2) Clean the data in snp.csv 
using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.
```{r}
snp <- read_csv("./data/snp.csv") |> 
  janitor::clean_names() |> 
  separate(date, into = c("month", "day", "year"), sep = "/") |> 
  mutate(
    year = as.integer(year),
    year = ifelse(year >= 50, 1900 + year, 2000 + year),
    month = as.integer(month),
    day = as.integer(day),
    month = month.abb[month]
  ) |>
  select(year,month,close) |>
  arrange(year, match(month, month.abb))
snp
```

#### (3) Tidy the unemployment data
This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.
```{r}
unemployment_tidy <- read_csv("./data/unemployment.csv") |> 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment_rate"
  ) |>
  mutate(
    unemployment_rate = as.numeric(unemployment_rate)
  ) |>
  rename(year = Year)
unemployment_tidy 
```

#### (4) Join the datasets by merging snp into pols, and merging unemployment into the result.
```{r}
data_0 <- pols_month |>
  left_join(snp, by = c("year", "month")) |>
  left_join(unemployment_tidy, by = c("year", "month")) |>
  arrange(year, match(month, month.abb))
data_0
```

Note(useing date variable)
```{r}
data_1 <- pols_month |>
  left_join(snp, by = c("year", "month")) |>
  left_join(unemployment_tidy, by = c("year", "month")) |>
  mutate(date = str_c(year, "-", sprintf("%02d", match(month, month.abb))))|> 
  relocate(date) |> 
  select(-year,-month) |> 
  arrange(date)
data_1
```

#### Write a short paragraph about these datasets. 
The final dataset combines three datasets tracking political and economic indicators. After cleaning and tidying three dataset separately, the pols-month dataset contains 822 observations of 9 variables related to the number of national politicians who are democratic or republican at any given time, including presidential party indicators and counts of politicians across governors, senators, and representatives; The snp dataset contains 787 observations of 3 variables related to Standard & Poor's stock market index, including the year and month of observation and closing values of the S&P stock index; The unemployment dataset contains 816 observations of 3 variables related to monthly unemployment percentages across different years, including the year of measurement and unemployment rates for each month from January to December. <br>
After merging three datasets, the resulting dataset contains 822 observations monthly spanning from 1947 to 2015 across 11 variables. Key variables include year, month, political composition indicators (gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem), presidential party, S&P closing values, unemployment rates. However, while the political data covers the full 1947-2015 period, the economic indicators have some missing values in earlier years, with S&P data beginning in 1950 and unemployment data in 1948. 


## Problem 2

#### Read and clean the sheet
Read and clean the Mr. Trash Wheel sheet<br>
1)specify the sheet in the Excel file and to omit non-data entries using arguments in read_excel<br>
2)use reasonable variable names<br>
3)omit rows that do not include dumpster-specific data<br>
4)round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)<br>
```{r}
mr_tidy <- read_excel("./data/202509 Trash Wheel Collection Data.xlsx", 
                       sheet = "Mr. Trash Wheel",
                       skip = 1,
                       na = c(".", "NA", "")) |>  
  janitor::clean_names() |>  
  filter(!is.na(dumpster)) |> 
  mutate(
    sports_balls = as.integer(round(sports_balls)), 
    year = as.integer(year)
  )
```

Read and clean Professor Trash Wheel data
```{r}
professor_tidy <- read_excel("./data/202509 Trash Wheel Collection Data.xlsx",
                        sheet = "Professor Trash Wheel",
                        skip = 1,
                        na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |> 
  mutate(
    year = as.integer(year)
  )
```

Read and clean Gwynnda data
```{r}
gwynnda_tidy <- read_excel("./data/202509 Trash Wheel Collection Data.xlsx",
                     sheet = "Gwynns Falls Trash Wheel",
                     skip = 1,
                     na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |> 
  mutate(
    year = as.integer(year)
  )
```

Add an additional variable to both datasets before combining
```{r}
mr_tidy <- mr_tidy |> 
  mutate(trash_wheel = "Mr. Trash Wheel")
professor_tidy <- professor_tidy |> 
  mutate(trash_wheel = "Professor Trash Wheel")
gwynnda_tidy <- gwynnda_tidy |> 
  mutate(trash_wheel = "Gwynnda")
```

#### Combine datasets
Combine this with the Mr. Trash Wheel dataset to produce a single tidy dataset
```{r}
combined_trash <- bind_rows(mr_tidy, professor_tidy, gwynnda_tidy) |> 
  select(where(~!all(is.na(.)))) |> 
  arrange(date)
combined_trash
```

#### Write a paragraph about these data
The resulting dataset combines trash collection data from three separate devices operating in Baltimore's Inner Harbor: Mr. Trash Wheel, Professor Trash Wheel, and Gwynns Falls Trash Wheel. The resulting dataset contains `r nrow(combined_trash)` observations tracking waste collection with `r ncol(combined_trash)` variables. Key variables include dumpster identification numbers, collection dates, total weight of trash, the number of some specific waste categories such as plastic bottles, polystyrene, cigarette butts, and the trash wheel identifier to track the source device.<br>(All the variables are:`r paste(names(combined_trash), collapse = ", ")`).<br><br>Based on the available data, the total weight of trash collected by Professor Trash Wheel is `r combined_trash |> filter(trash_wheel == "Professor Trash Wheel") |> summarise(total = sum(weight_tons, na.rm = TRUE)) |> pull(total)` tons. During June 2022, Gwynnda collected `r as.integer(combined_trash |> filter(trash_wheel == "Gwynnda", year == 2022, month == "June") |> summarise(total = sum(cigarette_butts, na.rm = TRUE)) |> pull(total))` cigarette butts.


## Problem 3
#### Import and clean
Import and clean ZIP code dataset
```{r}
zip_codes_tidy <- read_csv("./data/Zip Codes.csv",
                           na = c(".", "NA", ""))|>
  janitor::clean_names()|>  
  relocate(zip_code) |> 
  arrange(zip_code)
```

Import and clean ZIP ZORI dataset
```{r}
zip_zori <- read_csv("./data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv",
                     na = c(".", "NA", "")) |>
  janitor::clean_names()

zip_zori_tidy <- zip_zori |> 
  pivot_longer(
  cols = starts_with("x20"),
  names_to = "date",        
  values_to = "zori"        
  ) |>
  mutate(
    date = str_remove(date, "^x"),
    date = str_replace(date,"-","_")
    ) |>  
  relocate(region_name) |> 
  arrange(region_name)
```

#### Merge
Merge to create a single, final dataset
```{r}
resulting_tidy_data <- zip_zori_tidy |>
  left_join(zip_codes_tidy, by = c("region_name" = "zip_code")) |> 
  select(
    region_name, region_id, size_rank, region_type, 
    state_name, state, city, metro,county, county_name, 
    date, zori, county_code, county_fips, state_fips, file_date,neighborhood
  )
resulting_tidy_data
```

Check for completeness
```{r}
missing_zips <- zip_codes_tidy |>
  anti_join(zip_zori_tidy, by = c("zip_code" = "region_name")) |>
  select(zip_code, county, neighborhood)
```

#### Briefly describe the resulting tidy dataset. 
1.How many total observations exist? How many unique ZIP codes are included, and how many unique neighborhoods?<br>

The resulting tidy dataset contains `r nrow(resulting_tidy_data)` observations with `r ncol(resulting_tidy_data)` variables. The dataset spans from `r min(resulting_tidy_data$date)` to `r max(resulting_tidy_data$date)`, providing a comprehensive time series of Zillow rental price. All the variables in this dataset are: `r paste(names(combined_trash), collapse = ", ")`. <br>

Besides, the dataset includes `r n_distinct(resulting_tidy_data$region_name)` unique ZIP codes and `r n_distinct(na.omit(resulting_tidy_data$neighborhood))` unique neighborhoods across New York City. The structure also reveals that `r n_distinct(resulting_tidy_data$county)` distinct counties represented in the dataset. <br>


2.Which ZIP codes appear in the ZIP code dataset but not in the Zillow Rental Price dataset? Using a few illustrative examples discuss why these ZIP codes might be excluded from the Zillow dataset.

There are `r nrow(missing_zips)` ZIP codes that appear in the ZIP code dataset but not in the Zillow Rental Price dataset. Examples include `r paste(tail(missing_zips$zip_code, 3), collapse = ", ")`.The details of these three examples are following:<br>
-`r as.character(missing_zips$zip_code[169])` is located in `r as.character(missing_zips$county[169])`, specifically in the `r as.character(missing_zips$neighborhood[169])` neighborhood.<br>
-`r as.character(missing_zips$zip_code[170])` is located in `r as.character(missing_zips$county[170])`, specifically in the`r as.character(missing_zips$neighborhood[170])` neighborhood.<br>
-`r as.character(missing_zips$zip_code[171])` is located in `r as.character(missing_zips$county[171])`, specifically in the`r as.character(missing_zips$neighborhood[171])` neighborhood.<br>

These three examples located in the Rockaways area of Queens are likely excluded from the Zillow dataset. This exclusion is probably due to the following two reasons: firstly, their relatively remote location and lower population density lead to insufficient year-round rental transaction data, which does not meet Zillow's thresholds for inclusion in the dataset; secondly, the area may have a larger share of commercial or recreational area rather than residential areas, resulting in limited residential rental data.

#### Make a table and comment
For all available ZIP codes, compare rental prices in January 2021 to prices in January 2020. Make a table that shows the 10 ZIP codes (along with the borough and neighborhood) with largest drop in price from January 2020 to 2021. 

```{r}
covid_rental <- resulting_tidy_data |>
  filter(
    (date == "2020_01_31" | date == "2021_01_31")
  ) |>
  select(region_name, county, neighborhood, date, zori) |>
  pivot_wider(
    names_from = date,
    values_from = zori
  ) |>
  mutate(
    price_change = `2021_01_31` - `2020_01_31`,
    price_change_pct = (`2021_01_31` - `2020_01_31`) / `2020_01_31` * 100
  ) |>
  filter(!is.na(price_change)) |>
  arrange(price_change) |>
  head(10) |>
  rename(
    zip_code = region_name,
    borough = county,
    Jan_2020 = `2020_01_31`,
    Jan_2021 = `2021_01_31`
  ) |>
  select(zip_code, borough, neighborhood, Jan_2020, Jan_2021, price_change, price_change_pct)

cat("Top 10 ZIP codes with largest rental price drops from January 2020 to January 2021:\n")
covid_rental |>
  print()

table <- covid_rental |>
  mutate(
    across(c(Jan_2020, Jan_2021, price_change), ~round(., 2)),
    price_change_pct = round(price_change_pct, 2)
  ) |>
  rename(
    "ZIP Code" = zip_code,
    "Borough" = borough,
    "Neighborhood" = neighborhood,
    "Jan 2020" = Jan_2020,
    "Jan 2021" = Jan_2021,
    "Price Change" = price_change,
    "Pct Change %" = price_change_pct
  )

options(tibble.width = Inf)
table
```

Comment<br>
The data reveals a striking concentration of rental price declines in Manhattan during the COVID-19 pandemic, with all ten zip codes experiencing substantial percentage drops ranging from 14.4% to 22.4%. Particularly noteworthy is that Lower Manhattan areas (ZIP codes 10004, 10007, 10038) and the Lower East Side (10002, 10009) saw the most severe declines, with the largest percentage drop of 22.4% occurring in zip code 10004. This 
pattern shows that the impact of the epidemic is most obvious in high-density urban cores and communities that rely heavily on office workers and tourism, because the reduction of urban activities has greatly shifted the housing demand in these core areas.